# -*- coding: utf-8 -*-
"""Trade_Results_Analysis.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1wzg8tEf__ClqK5AqGIjXarhrnBEeGp2_

# Importing Libraries
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt

"""# Overview"""

df = pd.read_csv('atr_equity_curve_SOL.csv')
#df['Time'] = pd.to_datetime(df['Time'])
df.tail()

df['Capital'] = df['Capital'] - 100* (df.index + 1)

df['tp/sl'] = df['Capital'] - df['Capital'].shift(1)

df.loc[df.index==0, 'tp/sl'] = df['Capital']- 100000

df.head()

df['tp/sl'].sum()

df.head()

"""# Merged Process"""

coins = ['BTC','ETH','SOL','XRP','PEPE','DOGE']
dfs = {coin: pd.read_csv(f"atr_equity_curve_{coin}.csv") for coin in coins}

initial_capital = 100000  # Başlangıç sermayesi

for coin, df in dfs.items():
    # 'tp/sl' sütununu hesapla
    df['Capital'] = df['Capital'] - 65* (df.index + 1)
    df['tp/sl'] = df['Capital'] - df['Capital'].shift(1)

    # İlk satırı düzelt (Capital - initial_capital)
    df.loc[df.index == 0, 'tp/sl'] = df['Capital'].iloc[0] - initial_capital

    # Coin adını ekle (birleştirme için)
    df['coin'] = coin # Hangi coin'e ait olduğunu belirtmek için

# Tüm DataFrame'leri birleştir
combined_df = pd.concat(dfs.values(), ignore_index=True)

combined_df = combined_df.sort_values('Time')
combined_df['Time'] = pd.to_datetime(combined_df['Time'])
combined_df['Capital'] = combined_df['tp/sl'].cumsum()

"""# Explorer Data Analysis"""

combined_df['tp/sl'].sum() / 1000

combined_df.resample('M', on='Time')['tp/sl'].agg({'count','sum'})

combined_df.resample('M', on='Time')['tp/sl'].sum() / 1000

combined_df.resample('M', on='Time')['tp/sl'].count()

combined_df.count()

"""# Equity Curve"""

# ATR Steps
plt.figure(figsize=(12, 6))
plt.plot(pd.to_datetime(combined_df['Time']), combined_df['Capital'])
plt.title("Equity Curve Over Time")
plt.xlabel("Tarih")
plt.ylabel("Sermaye ($)")

# Y eksenini 10,000'er artacak şekilde ayarla
min_capital = int(combined_df['Capital'].min())
max_capital = int(combined_df['Capital'].max())
plt.yticks(range(min_capital - min_capital % 10000, max_capital + 10000, 10000))

plt.grid(True)
plt.tight_layout()
plt.show()

"""# Sharpe Ratio"""

def sharpe_ratio_from_capital(df, capital_col='Capital', time_col='Time', risk_free_rate=0.02, annualization_factor=252):
    """
    Bir DataFrame'deki kümülatif sermaye (capital) verisinden Sharpe Oranını hesaplar.

    :param df: Trade sonuçlarını içeren pandas DataFrame.
    :param capital_col: Toplam kar/zararı gösteren sütun adı (varsayılan: 'Capital').
    :param time_col: Tarih/saat bilgisini içeren sütun adı (varsayılan: 'Time').
    :param risk_free_rate: Yıllık risksiz faiz oranı (varsayılan: %2 = 0.02).
    :param annualization_factor: Yıllıklandırma faktörü (genellikle iş günü sayısı, varsayılan: 252).
    :return: Sharpe Oranı (float).
    """

    # 1. 'Time' sütununu datetime formatına çevir ve indeks yap
    df[time_col] = pd.to_datetime(df[time_col])
    df = df.set_index(time_col)

    # 2. Günlük kapanış sermaye değerlerini al
    # Burada, her günün son işlemindeki Capital değerini alıyoruz.
    daily_capital = df[capital_col].resample('D').last().dropna()

    # 3. Günlük getirileri hesapla
    # İlk getiriyi NaN yapmamak için .pct_change() kullanıyoruz, bu logaritmik getiri yerine basit getiri verir.
    daily_returns = daily_capital.pct_change().dropna()

    # 4. Ortalama günlük getiri ve standart sapma (volatilite) hesaplama
    avg_daily_return = daily_returns.mean()
    std_daily_return = daily_returns.std()

    # Eğer standart sapma 0 ise (getirilerde hiç değişim yoksa), tanımsız olmaması için büyük bir sayı dönebiliriz.
    if std_daily_return == 0:
        return np.inf if avg_daily_return > 0 else 0

    # 5. Sharpe Oranı Hesaplama
    # Sharpe Oranı = (Yıllık Ortalama Getiri - Risksiz Oran) / Yıllık Standart Sapma
    # Günlük verileri yıllıklandırma:
    # Getiri: Günlük Ortalama * annualization_factor
    # Volatilite: Günlük Standart Sapma * sqrt(annualization_factor)

    # Risksiz oranı günlük olarak çevirme (Genellikle risksiz oranı yıllık bırakıp formülde olduğu gibi yıllıklandırma yapılır)
    # Ancak finansal analizde, genellikle risksiz oran direkt yıllık bırakılır ve diğerleri yıllıklandırılır.

    # Yıllıklandırılmış Ortalama Getiri
    annualized_return = avg_daily_return * annualization_factor

    # Yıllıklandırılmış Volatilite
    annualized_volatility = std_daily_return * np.sqrt(annualization_factor)

    # Sharpe Oranı
    sharpe_ratio = (annualized_return - risk_free_rate) / annualized_volatility

    return sharpe_ratio

sharpe_ratio = sharpe_ratio_from_capital(combined_df, annualization_factor=365) # Because Cryptocurrencies

print(f"Sharpe Ratio: {sharpe_ratio:.4f}")



"""# Max Drawdown"""

def analyze_trade_performance(df, capital_col='Capital', time_col='Time'):
    """
    Calculates Maximum Drawdown (MDD) and Recovery Time from a time-series of capital.

    :param df: pandas DataFrame containing trade results.
    :param capital_col: The column name for the cumulative profit/loss (Capital).
    :param time_col: The column name for the date/time information (Time).
    :return: A dictionary containing MDD percentage, the start/end dates of the MDD,
             and the time taken for recovery (if applicable).
    """

    # 1. Prepare the Data
    df = df.copy()
    df[time_col] = pd.to_datetime(df[time_col])
    df = df.set_index(time_col)

    # Ensure the capital series is sequential
    capital_series = df[capital_col]

    # 2. Calculate Cumulative Maximum (Peak)
    # The running high-water mark of the capital.
    cumulative_max = capital_series.expanding(min_periods=1).max()

    # 3. Calculate Drawdown (as a percentage)
    # Drawdown = (Current Capital - Peak Capital) / Peak Capital
    drawdown_series = (capital_series - cumulative_max) / cumulative_max

    # 4. Find Maximum Drawdown (MDD)
    max_drawdown = drawdown_series.min() * 100

    # Locate the lowest point of the drawdown
    trough_date = drawdown_series.idxmin()
    trough_value = capital_series.loc[trough_date]

    # Find the peak just before the trough
    peak_capital_before_trough = cumulative_max.loc[:trough_date].iloc[-1]
    peak_date = capital_series[capital_series == peak_capital_before_trough].index[-1]

    # 5. Calculate Recovery Time

    # Find the capital value needed to recover (the peak value before the drawdown)
    recovery_target = capital_series.loc[peak_date]

    # Look for the first point after the trough date where capital exceeds or equals the recovery target
    recovery_data = capital_series.loc[trough_date:]

    # Filter for values that have recovered (Capital >= Recovery Target)
    recovered_points = recovery_data[recovery_data >= recovery_target]

    if not recovered_points.empty:
        # The date when the capital first hit the recovery target after the trough
        recovery_date = recovered_points.index[0]

        # Calculate the duration from the start of the drawdown (Peak Date)
        recovery_duration = recovery_date - peak_date
        recovery_info = {
            "recovery_date": recovery_date,
            "recovery_time": str(recovery_duration)
        }
    else:
        recovery_info = {
            "recovery_date": "N/A (Still in Drawdown)",
            "recovery_time": "N/A (Still in Drawdown)"
        }


    return {
        "max_drawdown_percent": f"{max_drawdown:.2f}%",
        "mdd_peak_date": peak_date.strftime('%Y-%m-%d %H:%M'),
        "mdd_trough_date": trough_date.strftime('%Y-%m-%d %H:%M'),
        "mdd_trough_value": trough_value,
        "recovery_time": recovery_info['recovery_time'],
        "recovery_date": recovery_info['recovery_date'].strftime('%Y-%m-%d %H:%M') if recovery_info['recovery_date'] != "N/A (Still in Drawdown)" else recovery_info['recovery_date']
    }

combined_df['Capital'] = combined_df['Capital'] + 100000
analysis_results = analyze_trade_performance(combined_df)

# Print results
print("--- Trade Performance Analysis ---")
print(f"Maximum Drawdown (MDD): {analysis_results['max_drawdown_percent']}")
print(f"MDD Peak Date: {analysis_results['mdd_peak_date']}")
print(f"MDD Trough Date: {analysis_results['mdd_trough_date']}")
print(f"Recovery Date: {analysis_results['recovery_date']}")
print(f"Recovery Time (Duration from Peak to Recovery): {analysis_results['recovery_time']}")